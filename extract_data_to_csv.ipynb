{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf871d92",
   "metadata": {},
   "source": [
    "# Extract data from dataset .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43546a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'content_name', 'STRRED', 'N_playback_frames', 'VMAF', 'SSIM', 'buffer_evolution_sec', 'height', 'playback_duration_sec', 'playout_bitrate', 'continuous_zscored_mos', 'scene_cuts_detected', 'PSNR', 'MSSIM', 'per_segment_encoding_QP', 'rebuffer_duration_sec', 'video_duration_sec', 'width', 'per_segment_encoding_height', 'selected_streams', 'distorted_mp4_video', 'adaptation_algorithm', 'rebuffer_number', 'content_spatial_information', 'content_temporal_information', 'frame_rate', 'per_segment_encoding_width', 'cropping_parameters', 'throughput_trace_name', 'content_name_acronym', 'scene_cuts', 'N_rebuffer_frames', 'is_rebuffered_bool', 'throughput_trace_kbps', 'reference_yuv_video', 'N_total_frames', 'retrospective_zscored_mos'])\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import glob\n",
    "import os\n",
    "\n",
    "mat_path = \"matdata/AirShow_HuangBufferBasedAdaptor_Trace_0.mat\"\n",
    "mat = loadmat(mat_path)\n",
    "print(mat.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13006f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_name: <class 'numpy.ndarray'>, shape: (1,)\n",
      "STRRED: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "N_playback_frames: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "VMAF: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "SSIM: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "buffer_evolution_sec: <class 'numpy.ndarray'>, shape: (1, 15)\n",
      "height: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "playback_duration_sec: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "playout_bitrate: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "continuous_zscored_mos: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "scene_cuts_detected: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "PSNR: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "MSSIM: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "per_segment_encoding_QP: <class 'numpy.ndarray'>, shape: (1, 15)\n",
      "rebuffer_duration_sec: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "video_duration_sec: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "width: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "per_segment_encoding_height: <class 'numpy.ndarray'>, shape: (1, 15)\n",
      "selected_streams: <class 'numpy.ndarray'>, shape: (1, 14)\n",
      "distorted_mp4_video: <class 'numpy.ndarray'>, shape: (1,)\n",
      "adaptation_algorithm: <class 'numpy.ndarray'>, shape: (1,)\n",
      "rebuffer_number: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "content_spatial_information: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "content_temporal_information: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "frame_rate: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "per_segment_encoding_width: <class 'numpy.ndarray'>, shape: (1, 15)\n",
      "cropping_parameters: <class 'numpy.ndarray'>, shape: (1,)\n",
      "throughput_trace_name: <class 'numpy.ndarray'>, shape: (1,)\n",
      "content_name_acronym: <class 'numpy.ndarray'>, shape: (1,)\n",
      "scene_cuts: <class 'numpy.ndarray'>, shape: (1, 14)\n",
      "N_rebuffer_frames: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "is_rebuffered_bool: <class 'numpy.ndarray'>, shape: (1, 814)\n",
      "throughput_trace_kbps: <class 'numpy.ndarray'>, shape: (1, 40)\n",
      "reference_yuv_video: <class 'numpy.ndarray'>, shape: (1,)\n",
      "N_total_frames: <class 'numpy.ndarray'>, shape: (1, 1)\n",
      "retrospective_zscored_mos: <class 'numpy.ndarray'>, shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for key in list(mat.keys())[3:]:\n",
    "    print(f\"{key}: {type(mat[key])}, shape: {mat[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d8fd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1392.1261477 , 1139.87237354,  993.08673267,  682.47833333,\n",
       "         678.10669111, 1041.3578635 ,  653.67779961,  759.70485437,\n",
       "         285.93882353,  234.00429752, 1057.52229931, 1158.73246753,\n",
       "        1505.62597403, 1610.09021956, 1085.84468719, 1015.64752475,\n",
       "        1368.97662338, 1137.21268583,  779.10857143,  390.9370297 ,\n",
       "         973.58961039,  715.31428571, 1019.22041217,  983.20998004,\n",
       "        1083.03555114, 1239.59762376,  735.81029703,  824.05069307,\n",
       "         539.65194805,  634.51337958,  420.69733333,  717.75584416,\n",
       "        1047.88503469,  842.32578497, 1641.6       , 1768.11948052,\n",
       "        1727.41727905, 1479.67462981, 1297.15988083,  884.84544564]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['throughput_trace_kbps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7983e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_flatten(mat_dict, key):\n",
    "    \"\"\"Return flattened array if key exists, else empty np.array().\"\"\"\n",
    "    return np.array(mat_dict[key]).flatten() if key in mat_dict else np.array([])\n",
    "\n",
    "def aggregate_to_seconds(df, fps=30):\n",
    "    \"\"\"Aggregate per-frame data to per-second averages.\"\"\"\n",
    "    n_seconds = len(df) // fps\n",
    "    grouped = []\n",
    "    for i in range(n_seconds):\n",
    "        chunk = df.iloc[i*fps:(i+1)*fps]\n",
    "        grouped.append({\n",
    "            \"second\": i,\n",
    "            \"mean_vmaf\": chunk[\"vmaf\"].mean(),\n",
    "            \"mean_psnr\": chunk[\"psnr\"].mean(),\n",
    "            \"mean_ssim\": chunk[\"ssim\"].mean(),\n",
    "            \"mean_strred\": chunk[\"strred\"].mean(),\n",
    "            \"mean_bitrate\": chunk[\"bitrate\"].mean(),\n",
    "            \"rebuffer_fraction\": chunk[\"is_rebuffered\"].mean(),\n",
    "            \"mean_cont_mos\": chunk[\"continuous_mos\"].mean(),\n",
    "        })\n",
    "    return pd.DataFrame(grouped)\n",
    "\n",
    "def extract_features_from_mat(mat_path):\n",
    "    mat = loadmat(mat_path)\n",
    "    vmaf = safe_flatten(mat, \"VMAF\")\n",
    "    psnr = safe_flatten(mat, \"PSNR\")\n",
    "    ssim = safe_flatten(mat, \"SSIM\")\n",
    "    strred = safe_flatten(mat, \"STRRED\")\n",
    "    bitrate = safe_flatten(mat, \"playout_bitrate\")\n",
    "    rebuffer = safe_flatten(mat, \"is_rebuffered_bool\")\n",
    "    cont_mos = safe_flatten(mat, \"continuous_zscored_mos\")\n",
    "\n",
    "    # Align lengths\n",
    "    n = min(len(vmaf), len(psnr), len(ssim), len(bitrate), len(cont_mos))\n",
    "    df = pd.DataFrame({\n",
    "        \"vmaf\": vmaf[:n],\n",
    "        \"psnr\": psnr[:n],\n",
    "        \"ssim\": ssim[:n],\n",
    "        \"strred\": strred[:n] if len(strred) >= n else np.nan,\n",
    "        \"bitrate\": bitrate[:n],\n",
    "        \"is_rebuffered\": rebuffer[:n] if len(rebuffer) >= n else np.zeros(n),\n",
    "        \"continuous_mos\": cont_mos[:n]\n",
    "    })\n",
    "\n",
    "    # Per-second aggregation: ensure fps is a scalar integer (fallback to 30)\n",
    "    fps_arr = safe_flatten(mat, \"frame_rate\")\n",
    "    try:\n",
    "        fps = int(np.asarray(fps_arr).flatten()[0]) if fps_arr.size > 0 else 30\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        fps = 30\n",
    "    sec_df = aggregate_to_seconds(df, fps)\n",
    "\n",
    "    # Metadata (video-level)\n",
    "    sec_df[\"video_name\"] = os.path.basename(mat_path).replace(\".mat\", \"\")\n",
    "    sec_df[\"content_name\"] = str(safe_flatten(mat, \"content_name\")[0]) if \"content_name\" in mat else None\n",
    "    sec_df[\"adaptation_algorithm\"] = str(safe_flatten(mat, \"adaptation_algorithm\")[0]) if \"adaptation_algorithm\" in mat else None\n",
    "    sec_df[\"throughput_trace\"] = str(safe_flatten(mat, \"throughput_trace_name\")[0]) if \"throughput_trace_name\" in mat else None\n",
    "    sec_df[\"spatial_info\"] = float(safe_flatten(mat, \"content_spatial_information\")[0]) if \"content_spatial_information\" in mat else np.nan\n",
    "    sec_df[\"temporal_info\"] = float(safe_flatten(mat, \"content_temporal_information\")[0]) if \"content_temporal_information\" in mat else np.nan\n",
    "    sec_df[\"rebuffer_duration_sec\"] = float(safe_flatten(mat, \"rebuffer_duration_sec\")[0]) if \"rebuffer_duration_sec\" in mat else np.nan\n",
    "    sec_df[\"retrospective_mos\"] = float(safe_flatten(mat, \"retrospective_zscored_mos\")[0]) if \"retrospective_zscored_mos\" in mat else np.nan\n",
    "    return sec_df\n",
    "\n",
    "# --- Process all .mat files\n",
    "all_files = glob.glob(\"matdata/*.mat\")\n",
    "all_dfs = [extract_features_from_mat(f) for f in all_files]\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "final_df.to_csv(\"data/data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qoe_predict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
